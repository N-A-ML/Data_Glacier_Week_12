{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bad04e",
   "metadata": {},
   "source": [
    "<font color=\"blue\" size=\"5px\"> This is the modelling component of the final project for the internship with Data Glacier. We will explore various models. ROC-AUC will be used as the main scoring metric, since the classes in the target are somewhat imbalanced </font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d0f02",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\"> Let's begin by importing each dataset, shuffling and defining new dataframes: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce534ca",
   "metadata": {},
   "source": [
    "Import, shuffle and reset index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6bff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_modified=pd.read_csv(r'df_modified.csv', engine='python').sample(frac=1).reset_index(drop=True) #cleaned dataset, with some rows (with outliers) removed\n",
    "df_modified2= pd.read_csv(r'df_modified_all_rows.csv', engine='python').sample(frac=1).reset_index(drop=True) #cleaned dataset but without rows (with outliers) removed - has been created for the modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b20e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1215, 115) (3424, 115)\n"
     ]
    }
   ],
   "source": [
    "print(df_modified.shape,df_modified2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fb6ca",
   "metadata": {},
   "source": [
    "Let's create a dataframes with the 6 best features (found in weeks 8-9) and the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9f900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_best = [df_modified[\"Dexa_During_Rx_Y\"] , df_modified[\"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\"], df_modified[\"Comorb_Encounter_For_Immunization_Y\"] , df_modified[\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\"] , df_modified[\"Comorb_Long_Term_Current_Drug_Therapy_Y\"] , df_modified[\"Concom_Viral_Vaccines_Y\"], df_modified[\"Persistency_Flag_Persistent\"]]\n",
    "headers = [\"Dexa_During_Rx_Y\" , \"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\", \"Comorb_Encounter_For_Immunization_Y\" ,\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\" , \"Comorb_Long_Term_Current_Drug_Therapy_Y\" , \"Concom_Viral_Vaccines_Y\", \"Persistency_Flag_Persistent\"]\n",
    "df_best=pd.concat(data_best, axis=1, keys=headers)\n",
    "\n",
    "data_best2 = [df_modified2[\"Dexa_During_Rx_Y\"] , df_modified2[\"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\"], df_modified2[\"Comorb_Encounter_For_Immunization_Y\"] , df_modified2[\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\"] , df_modified2[\"Comorb_Long_Term_Current_Drug_Therapy_Y\"] , df_modified2[\"Concom_Viral_Vaccines_Y\"], df_modified2[\"Persistency_Flag_Persistent\"]]\n",
    "headers = [\"Dexa_During_Rx_Y\" , \"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\", \"Comorb_Encounter_For_Immunization_Y\" ,\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\" , \"Comorb_Long_Term_Current_Drug_Therapy_Y\" , \"Concom_Viral_Vaccines_Y\", \"Persistency_Flag_Persistent\"]\n",
    "df_best2=pd.concat(data_best2, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae98ae",
   "metadata": {},
   "source": [
    "Let's create a way to quickly evaluate a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate():\n",
    "    print('Precision score is {}'.format(precision_score(y_test,preds, average='macro'))) #use macro scoring since classes are imbalanced\n",
    "    print('Recall score is {}'.format(recall_score(y_test,preds, average='macro'))) #use macro scoring since classes are imbalanced\n",
    "    print('F1 score is {}'.format(f1_score(y_test,preds, average='macro'))) #use macro scoring since classes are imbalanced\n",
    "    print('Accuracy score is {}'.format(accuracy_score(y_test,preds))) \n",
    "    print('ROC_AUC score is {}'.format(roc_auc_score(y_test,preds))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b170c2",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\"> We will test each dataset on a basic logistic regression model and choose the best dataset for upcoming modelling </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4fb9e",
   "metadata": {},
   "source": [
    "First let's try using the cleaned data, without outliers removed, and with all of the features with a basic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04d8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#let the feature dataframe contain every column of df, except the value we are predicting,Persistency_Flag_Persistent\n",
    "X=df_modified2.loc[:,df_modified2.columns!=\"Persistency_Flag_Persistent\"]\n",
    "#let the target array contain only the value we are predicting, Persistency_Flag_Persistent\n",
    "# y=df.loc[:,df.columns==\"heart_disease\"].values.ravel()\n",
    "y=df_modified2.loc[:,df_modified2.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=123)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7c6b3",
   "metadata": {},
   "source": [
    "Let's create an evaluate a simple logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851f2dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.815209969639322\n",
      "Recall score is 0.7955943943298969\n",
      "F1 score is 0.8029171740200522\n",
      "Accuracy score is 0.8200389105058365\n",
      "ROC_AUC score is 0.7955943943298969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085853b5",
   "metadata": {},
   "source": [
    "Let's try again, but with outliers removed and still using all of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac04ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.8579789775441949\n",
      "Recall score is 0.8142168169427553\n",
      "F1 score is 0.8309308530349069\n",
      "Accuracy score is 0.863013698630137\n",
      "ROC_AUC score is 0.8142168169427553\n"
     ]
    }
   ],
   "source": [
    "X=df_modified.loc[:,df_modified.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_modified.loc[:,df_modified.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=123)   \n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72efb3",
   "metadata": {},
   "source": [
    "We used SelectKBest in weeks 8-9 to find the best 6 features. Let's test the dataframe with just the 6 best features and target, and outliers removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e786dc7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-856f6e8d716f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m\"Persistency_Flag_Persistent\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"Persistency_Flag_Persistent\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_best' is not defined"
     ]
    }
   ],
   "source": [
    "X=df_best.loc[:,df_best.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_best.loc[:,df_best.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=123)   \n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9c176",
   "metadata": {},
   "source": [
    "Let's test the dataframe with just the 6 best features and target, and outliers included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f60c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7827376880984952\n",
      "Recall score is 0.7663418170103093\n",
      "F1 score is 0.7724496888653516\n",
      "Accuracy score is 0.791828793774319\n",
      "ROC_AUC score is 0.7663418170103093\n"
     ]
    }
   ],
   "source": [
    "X=df_best2.loc[:,df_best2.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_best2.loc[:,df_best2.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=123) \n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdae0c",
   "metadata": {},
   "source": [
    "The df_best dataset seemed to be the best overall to me, based on the evaluation metrics (e.g., high accuracy), and also, there are only 6 features and lower number of rows, so using this data would be computationally efficient, especially since we will be doing some grid searching.We will use this dataset in all future modelling. Also, only needing 6 features to predict persistency may be very useful for the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01dd404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dexa_During_Rx_Y</th>\n",
       "      <th>Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y</th>\n",
       "      <th>Comorb_Encounter_For_Immunization_Y</th>\n",
       "      <th>Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y</th>\n",
       "      <th>Comorb_Long_Term_Current_Drug_Therapy_Y</th>\n",
       "      <th>Concom_Viral_Vaccines_Y</th>\n",
       "      <th>Persistency_Flag_Persistent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dexa_During_Rx_Y  Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y  \\\n",
       "0               0.0                                                1.0          \n",
       "1               0.0                                                0.0          \n",
       "2               1.0                                                1.0          \n",
       "3               0.0                                                1.0          \n",
       "4               0.0                                                1.0          \n",
       "\n",
       "   Comorb_Encounter_For_Immunization_Y  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  1.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y  \\\n",
       "0                                                1.0                   \n",
       "1                                                0.0                   \n",
       "2                                                1.0                   \n",
       "3                                                0.0                   \n",
       "4                                                1.0                   \n",
       "\n",
       "   Comorb_Long_Term_Current_Drug_Therapy_Y  Concom_Viral_Vaccines_Y  \\\n",
       "0                                      0.0                      0.0   \n",
       "1                                      0.0                      0.0   \n",
       "2                                      1.0                      0.0   \n",
       "3                                      0.0                      0.0   \n",
       "4                                      1.0                      0.0   \n",
       "\n",
       "   Persistency_Flag_Persistent  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          1.0  \n",
       "3                          0.0  \n",
       "4                          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84715ca6",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\"> Now that we have chosen the best dataset to use, let's try to optimise our logistic regression model    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea1b26",
   "metadata": {},
   "source": [
    "Let's check the base model's cross-val scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bd3faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores are: [0.81685215 0.86518283 0.90429253 0.92114467 0.85557644 0.77992278\n",
      " 0.82915058 0.92792793 0.8264157  0.84169884]\n",
      "The mean cross-validation score is:0.8568164449278999\n"
     ]
    }
   ],
   "source": [
    "X=df_best.loc[:,df_best.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_best.loc[:,df_best.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=123)  \n",
    "\n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "scores = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f793a",
   "metadata": {},
   "source": [
    "It looks like the base model is good at generalising to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77107a97",
   "metadata": {},
   "source": [
    "Let's optimise the logistic regression model on df_best (uncomment to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0169845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# logreg = LogisticRegression(max_iter=1000000,\n",
    "#                      n_jobs=-1)\n",
    "\n",
    "# params={\"C\":[0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle = False) # make sure class balance in each fold is the same as in the orginal dataset\n",
    "\n",
    "# grid_search=GridSearchCV(logreg,params,cv=skf.split(X_train,y_train),scoring='roc_auc')\n",
    "\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# #print(grid_search.cv_results_)\n",
    "# print(grid_search.best_score_, grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97369135",
   "metadata": {},
   "source": [
    "We now have a logistic regression model with optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9012379",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_new=LogisticRegression(C=1, max_iter=1000000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36cc79",
   "metadata": {},
   "source": [
    "Let's use the best parameters (i.e., the ones yielding the highest average cross-validation score, 0.867) from grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f55a10e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.8178571428571428\n",
      "Recall score is 0.7643810722024184\n",
      "F1 score is 0.7823865088152628\n",
      "Accuracy score is 0.8273972602739726\n",
      "ROC_AUC score is 0.7643810722024185\n"
     ]
    }
   ],
   "source": [
    "logreg_new=LogisticRegression(C=1, max_iter=1000000, n_jobs=-1).fit(X_train,y_train)\n",
    "preds=logreg_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ca815",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\"> Let's create an XGB classifier and find the best hyperparameters: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9df11",
   "metadata": {},
   "source": [
    "Let's create an XGB Classifier with mostly default paramters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef8f9a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores are: [0.83147854 0.84292528 0.90572337 0.91446741 0.85870927 0.79086229\n",
      " 0.83848134 0.93468468 0.82158945 0.78474903]\n",
      "The mean cross-validation score is:0.8523670663144347\n",
      "Precision score is 0.8171054712207464\n",
      "Recall score is 0.7803348011462921\n",
      "F1 score is 0.7943396052133271\n",
      "Accuracy score is 0.8328767123287671\n",
      "ROC_AUC score is 0.7803348011462921\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier(eval_metric='mlogloss',use_label_encoder=False)\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "#check cross val scores:\n",
    "\n",
    "scores = cross_val_score(xgb, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))\n",
    "\n",
    "preds=xgb.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd5ff4",
   "metadata": {},
   "source": [
    "We ran grid searches with various parameters ranges and attempted to find the best set of parameters (uncomment to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc06aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# xgb = XGBClassifier(#learning_rate=0.03, \n",
    "#     #n_estimators=1000, objective='binary:logistic',\n",
    "#                      n_jobs=-1, use_label_encoder=False)\n",
    "\n",
    "# params = {\n",
    "#              'learning_rate':[0.3],\n",
    "#              'n_estimators':[50,100], \n",
    "#              'min_child_weight': [1, 5, 10],\n",
    "#              'gamma': [0, 1, 2],\n",
    "#              'subsample': [0.6, 0.8, 1.0],\n",
    "#              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#              'max_depth': [3,4]\n",
    "#         }\n",
    "\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "\n",
    "# grid_search = GridSearchCV(xgb, param_grid=params,  \n",
    "#                              scoring='roc_auc', n_jobs=-1, cv=skf.split(X_train,y_train), verbose=3\n",
    "#                             )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# #print(grid_search.cv_results_)\n",
    "\n",
    "# print(grid_search.best_score_, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73298d02",
   "metadata": {},
   "source": [
    "We shall use the best parameters (those yielding the highest average cross val score(0.870)) from grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae2a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.8225146198830409\n",
      "Recall score is 0.7891067309708535\n",
      "F1 score is 0.8022297936430677\n",
      "Accuracy score is 0.8383561643835616\n",
      "ROC_AUC score is 0.7891067309708534\n"
     ]
    }
   ],
   "source": [
    "xgb_new=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=2, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=5, #missing=nan,\n",
    "              monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.6,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None,\n",
    "                     eval_metric='mlogloss' #specify eval metric to avoid warnings \n",
    "                     )\n",
    "\n",
    "xgb_new.fit(X_train,y_train)\n",
    "\n",
    "#test on test data now:\n",
    "preds=xgb_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fa3f6",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\">  Let's create a neural network and optimise its hyperparameters: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30e367",
   "metadata": {},
   "source": [
    "Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf2f6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "import tensorflow\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f9f57",
   "metadata": {},
   "source": [
    "Define the network architecture and wrapper for KerasClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a2a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(optimizer='uniform', init='adam'):\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(5, input_dim=X_train.shape[1], activation='relu')) #let's use 2/3 size of input layer + size of output layer for number of nodes\n",
    "    nn.add(Dense(5, activation='relu'))\n",
    "    nn.add(Dense(1, activation='relu'))\n",
    "    nn.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "               #metrics='roc-auc'\n",
    "              )\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3094ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn=KerasClassifier(build_fn=create_nn, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e8be4",
   "metadata": {},
   "source": [
    "We used grid search to search for optimal parameters (we used various ranges and narrowed the parameters down). Uncomment to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "optimizers = [#'rmsprop',\n",
    "    'adam'\n",
    "]\n",
    "init = [#'glorot_uniform'\n",
    "    #'normal',\n",
    "         'uniform'\n",
    "]\n",
    "epochs = [150]\n",
    "batches = [5,10]\n",
    "\n",
    "params = dict(optimizer=optimizers, epochs=epochs, \n",
    "                  batch_size=batches,\n",
    "                  init=init)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nn, param_grid=params, n_jobs=-1, cv=skf.split(X_train,y_train))\n",
    "grid_search = grid_search.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351891b5",
   "metadata": {},
   "source": [
    "Let's use the params which acheived the best average cross-validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8623b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_new=KerasClassifier(build_fn=create_nn, verbose=0,batch_size=5, epochs=150, init='uniform', optimizer='adam')\n",
    "nn_new._estimator_type=\"classifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b26505",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b42191e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2069cdcf940>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_new.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "941cfd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_new.model.save('neural_network_best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24ce34",
   "metadata": {},
   "source": [
    "Predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "071ad4fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natha\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.8138367441144791\n",
      "Recall score is 0.7851226672258336\n",
      "F1 score is 0.7966833776219306\n",
      "Accuracy score is 0.8328767123287671\n",
      "ROC_AUC score is 0.7851226672258336\n"
     ]
    }
   ],
   "source": [
    "preds = nn_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e63214",
   "metadata": {},
   "source": [
    "Best: 0.793230 using {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4df652",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\"> Let's create a random forest and find the best hyperparameters: </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fb418",
   "metadata": {},
   "source": [
    "Let's create a random forest classifier with default settings and check the cross val scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8fc39",
   "metadata": {},
   "source": [
    "Train, predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de928908",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)\n",
    "preds=rf.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import GridSearchCV\n",
    "# # from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# params= {'bootstrap': [True],\n",
    "#  'max_depth': [11],\n",
    "#  'max_features': ['auto'],\n",
    "#  'min_samples_leaf': [7,8],\n",
    "#  'min_samples_split': [9,10],\n",
    "#  'n_estimators': [1000]}\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=params, n_jobs=-1, scoring='roc_auc' ,cv=skf.split(X_train,y_train))\n",
    "# grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_score_,grid_search.best_params_)\n",
    "# #print(grid_search.cv_results_)\n",
    "# #grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5ba60",
   "metadata": {},
   "source": [
    "The best average cross-val score was 0.864. Let's use the estimator which achieved this score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_new=RandomForestClassifier(**{'bootstrap': True, 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 1000})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe54fd",
   "metadata": {},
   "source": [
    "Train, predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_new.fit(X_train,y_train)\n",
    "preds=rf_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783877",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\">Let's create a K nearest neighbors classifier and find the best value for K: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32031c08",
   "metadata": {},
   "source": [
    "Let's define a KNN with default parameters, and check the cross-validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112549b",
   "metadata": {},
   "source": [
    "cross-val scores are quite close together, except for the 0.63 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afd3fd",
   "metadata": {},
   "source": [
    "let's train the knn and predict and evaluate on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train,y_train)\n",
    "preds=knn.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,preds)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51cb277",
   "metadata": {},
   "source": [
    "Let's create a grid search to find the best value of K (uncomment to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e084e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import GridSearchCV\n",
    "# # from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# params = {\n",
    "#     'n_neighbors':n_neigh\n",
    "# }\n",
    "\n",
    "# # skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "#n_neigh=[i for i in range(1,33) if i%2!=0]\n",
    "# grid_search = GridSearchCV(estimator=knn, param_grid=params, n_jobs=-1, scoring='roc_auc' ,cv=skf.split(X_train,y_train))\n",
    "# grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_score_,grid_search.best_params_)\n",
    "# #print(grid_search.cv_results_)\n",
    "# #grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756421e",
   "metadata": {},
   "source": [
    "let's use the parameters with the highest average cross-val score (0.853) and predict and evalute on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72baf049",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_new=KNeighborsClassifier(n_neighbors=31)\n",
    "preds=knn.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c90453",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\">Let's use stacking: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883619c",
   "metadata": {},
   "source": [
    "Let's use the top 3 estimators (from the code blocks above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_new=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=2, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=5, #missing=nan,\n",
    "              monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.6,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None,\n",
    "                     eval_metric='mlogloss' #specify eval metric to avoid warnings \n",
    "                     )\n",
    "\n",
    "nn_new=KerasClassifier(build_fn=create_nn, verbose=0,batch_size=5, epochs=150, init='uniform', optimizer='adam')\n",
    "nn_new._estimator_type=\"classifier\"\n",
    "\n",
    "rf_new=RandomForestClassifier(**{'bootstrap': True, 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bc9bd",
   "metadata": {},
   "source": [
    "Define the splitting method and declare the estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb14f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "estimators=[('xgb_new', xgb_new), ('nn_new', nn_new), ('rf_new',rf_new)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13951f34",
   "metadata": {},
   "source": [
    "Define the stacking model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa56e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    cv=skf.split(X_train,y_train))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f6bca",
   "metadata": {},
   "source": [
    "Fit to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bdb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8b3da",
   "metadata": {},
   "source": [
    "Predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=sc.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b1164",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"5px\">Let's use voting: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9185ca",
   "metadata": {},
   "source": [
    "Let's define the voting classifier model. The neural network performed well so we will give it a relatively high weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators= [('xgb_new', xgb_new),\n",
    "                                   ('nn_new', nn_new), \n",
    "                                   ('rf_new',rf_new)], \n",
    "                      voting='soft', #vote based on probabilities rather than majority vote of classes\n",
    "                      weights=[1,2,1] #assign weights: xgboost performed very well so we'll give it a relatively high weight\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc9747",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9668227",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f88be5",
   "metadata": {},
   "source": [
    "Predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=vc.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018e0e7",
   "metadata": {},
   "source": [
    "<font color=\"green\" size=\"5px\">Which model is best? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ce739",
   "metadata": {},
   "source": [
    "The XGB classifier (xgb_new) was definitely a good model, with solid scores overall, and some relatively high precision and recall scores. The default model for xgb boost had a good cross-validation score and this wasn't found to change significantly after parameter tuning.  The neural network (nn_new) performed slightly better (or the same) compared to xgb_new in general. The random forest (rf_new) also performed well but was slighly worse than the other models. Both the voting classifer (vc) and stacking classifer (sc) performed well in general but weren't better than nn_new. Overall the best model is nn_new."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7a536",
   "metadata": {},
   "source": [
    "These are the evaluation metrics for nn_new on the test data when I ran the code (we found these earlier):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision score 0.8175742386268702\")\n",
    "print(\"Recall score is 0.777711363485422\")\n",
    "print(\"F1 score is 0.7911991199119912\")\n",
    "print(\"Accuracy score is 0.821917808219178\")\n",
    "print(\"ROC_AUC score is 0.777711363485422\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa26182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2396, 114)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19750458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dexa_During_Rx_Y</th>\n",
       "      <th>Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y</th>\n",
       "      <th>Comorb_Encounter_For_Immunization_Y</th>\n",
       "      <th>Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y</th>\n",
       "      <th>Comorb_Long_Term_Current_Drug_Therapy_Y</th>\n",
       "      <th>Concom_Viral_Vaccines_Y</th>\n",
       "      <th>Persistency_Flag_Persistent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dexa_During_Rx_Y  Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y  \\\n",
       "0               0.0                                                0.0          \n",
       "1               0.0                                                0.0          \n",
       "2               0.0                                                1.0          \n",
       "3               1.0                                                1.0          \n",
       "4               0.0                                                1.0          \n",
       "\n",
       "   Comorb_Encounter_For_Immunization_Y  \\\n",
       "0                                  1.0   \n",
       "1                                  0.0   \n",
       "2                                  1.0   \n",
       "3                                  1.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y  \\\n",
       "0                                                0.0                   \n",
       "1                                                1.0                   \n",
       "2                                                1.0                   \n",
       "3                                                0.0                   \n",
       "4                                                0.0                   \n",
       "\n",
       "   Comorb_Long_Term_Current_Drug_Therapy_Y  Concom_Viral_Vaccines_Y  \\\n",
       "0                                      0.0                      0.0   \n",
       "1                                      0.0                      0.0   \n",
       "2                                      0.0                      0.0   \n",
       "3                                      0.0                      0.0   \n",
       "4                                      0.0                      0.0   \n",
       "\n",
       "   Persistency_Flag_Persistent  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          1.0  \n",
       "4                          1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bc4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
